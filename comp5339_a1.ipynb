{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinyjib98/comp5339/blob/main/comp5339_a1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "DZ1LnQ-Gmgc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "DZ1LnQ-Gmgc7",
        "outputId": "39dd155d-948b-4568-88d3-db735eb3d0f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (4.35.0)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from selenium) (2025.8.3)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Requirement already satisfied: pyperclip in /Users/hyungjinkim/opt/anaconda3/envs/comp5339/lib/python3.12/site-packages (1.10.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!pip install pyperclip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "43e4126b",
      "metadata": {
        "id": "43e4126b"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import time\n",
        "import pyperclip\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.options import Options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af8e8f71",
      "metadata": {
        "id": "af8e8f71"
      },
      "outputs": [],
      "source": [
        "class DataRetriever:\n",
        "    def __init__(self, output_dir='./data'):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
        "        })\n",
        "        self.driver = None\n",
        "        self.wait = None\n",
        "\n",
        "    # Download a file using HTTP request\n",
        "    def download_file_http(self, url, filename, subfolder):\n",
        "\n",
        "        try:\n",
        "            save_dir = self.output_dir / subfolder\n",
        "            save_dir.mkdir(exist_ok=True) # Create subfolder if it doesn't exist\n",
        "            filepath = save_dir / filename\n",
        "\n",
        "            print(f'Downloading: {filename}')\n",
        "            print(f'From: {url}')\n",
        "\n",
        "            response = self.session.get(url, stream=True, timeout=30)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            with open(filepath, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "\n",
        "            print(f'Downloaded: {filename}')\n",
        "            return filepath\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'Failed to download {filename}: {str(e)}')\n",
        "            return None\n",
        "\n",
        "    # Set up Selenium driver\n",
        "    def setup_selenium_driver(self, subfolder):\n",
        "            # Set up Chrome options for Selenium script\n",
        "            chrome_options = Options()\n",
        "            chrome_options.add_argument(\"--headless\")\n",
        "\n",
        "            # Specify anti-detection options\n",
        "            chrome_options.add_argument(\"--disable-web-security\")\n",
        "            chrome_options.add_argument(\"--allow-running-insecure-content\")\n",
        "            chrome_options.add_argument(\"--disable-extensions\")\n",
        "            chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "            chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "            chrome_options.add_experimental_option('useAutomationExtension', False)\n",
        "            chrome_options.add_argument(\"--no-sandbox\")\n",
        "            chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "            chrome_options.add_argument(\"--disable-gpu\")\n",
        "            chrome_options.add_argument(\"--window-size=1920,1080\")\n",
        "\n",
        "            # Set download directory\n",
        "            download_path = str((self.output_dir / subfolder).absolute())\n",
        "            Path(download_path).mkdir(exist_ok=True)\n",
        "            print(f'Setting download directory to: {download_path}')\n",
        "\n",
        "            prefs = {\n",
        "                \"download.default_directory\": download_path,\n",
        "                \"download.prompt_for_download\": False,\n",
        "                \"download.directory_upgrade\": True,\n",
        "                \"safebrowsing.enabled\": True,\n",
        "                \"safebrowsing.disable_download_protection\": True,\n",
        "                \"download.extensions_to_open\": \"\",\n",
        "                \"download.open_pdf_in_system_reader\": False,\n",
        "                \"plugins.always_open_pdf_externally\": True\n",
        "            }\n",
        "\n",
        "            chrome_options.add_experimental_option(\"prefs\", prefs)\n",
        "\n",
        "            # Initialise WebDriver\n",
        "            try:\n",
        "                self.driver = webdriver.Chrome(options=chrome_options)\n",
        "                self.wait = WebDriverWait(self.driver, 80)\n",
        "                print('Chrome WebDriver initialized')\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                print(f'Failed to initialize WebDriver: {str(e)}')\n",
        "                return False\n",
        "\n",
        "    # Close WebDriver\n",
        "    def close_driver(self):\n",
        "\n",
        "        if self.driver:\n",
        "            self.driver.quit()\n",
        "            self.driver = None\n",
        "            self.wait = None\n",
        "\n",
        "    # Specify timeout for download\n",
        "    def wait_for_download(self, download_dir, timeout=120):\n",
        "        print('Waiting for download to complete...')\n",
        "\n",
        "        start_time = time.time()\n",
        "        initial_files = set(os.listdir(download_dir))\n",
        "\n",
        "        while time.time() - start_time < timeout:\n",
        "            current_files = set(os.listdir(download_dir))\n",
        "            new_files = current_files - initial_files\n",
        "\n",
        "            if new_files:\n",
        "                # Check if any files are still downloading (.crdownload extension)\n",
        "                downloading = [f for f in new_files if f.endswith('.crdownload')]\n",
        "                if not downloading:\n",
        "                    print(f'Download complete: {list(new_files)}')\n",
        "                    return list(new_files)\n",
        "\n",
        "            # Show progress every 10 seconds\n",
        "            elapsed = time.time() - start_time\n",
        "            if int(elapsed) % 10 == 0 and elapsed > 0:\n",
        "                print(f'Waiting... ({elapsed:.0f}s elapsed)')\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "        print(f'Download timeout after {timeout} seconds')\n",
        "        return []\n",
        "\n",
        "    # Retrieve NGER data\n",
        "    def retrieve_cer_nger_data(self):\n",
        "        '''\n",
        "        How it works:\n",
        "        Find the API Copy button and click it\n",
        "        '''\n",
        "        print('\\n=== Task 1: Retrieving CER NGER Data ===')\n",
        "\n",
        "        if not self.setup_selenium_driver('cer_nger'):\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            url = 'https://data.cer.gov.au/datasets/NGER/ID0243'\n",
        "            print(f\"Loading: {url}\")\n",
        "            self.driver.get(url)\n",
        "\n",
        "            # Wait for page to load\n",
        "            self.wait.until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
        "            time.sleep(5)  # Wait for dynamic content to load\n",
        "\n",
        "            # Set window size\n",
        "            self.driver.set_window_size(1920, 1080)\n",
        "            time.sleep(1)\n",
        "\n",
        "            api_button = self.wait.until(EC.element_to_be_clickable((By.XPATH, \"//span[contains(@class,'cer-button-text') and contains(text(),'Copy API URL')]/ancestor::button\")))\n",
        "\n",
        "            api_url = self.driver.execute_script(\"\"\"\n",
        "                                                    var btn = [...document.querySelectorAll('span.cer-button-text')]\n",
        "                                                        .find(el => el.textContent.includes('Copy API URL'));\n",
        "                                                    if (btn) {\n",
        "                                                        return btn.closest('button').getAttribute('data-clipboard-text');\n",
        "                                                    }\n",
        "                                                    return null;\n",
        "                                                \"\"\")\n",
        "            if not api_url:\n",
        "                api_button.click()\n",
        "                api_url = pyperclip.paste()\n",
        "            \n",
        "            print(f\"API URL: {api_url}\")\n",
        "            \n",
        "            api_call = requests.get(api_url, timeout = 120)\n",
        "            api_call.raise_for_status()\n",
        "            nger_json = api_call.json()\n",
        "\n",
        "\n",
        "            df = pd.DataFrame(nger_json)\n",
        "\n",
        "            download_dir = self.output_dir / 'cer_nger'\n",
        "            download_dir.mkdir(exist_ok = True)\n",
        "            filepath = download_dir / 'NGER.ID0243.csv'\n",
        "            df.to_csv(filepath, index = False)\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"Error retrieving NGER data: {str(e)}\")\n",
        "\n",
        "        finally:\n",
        "            self.close_driver()\n",
        "\n",
        "\n",
        "    # Retrieve CER Renewable Energy Data\n",
        "    def retrieve_cer_renewable_data(self):\n",
        "        '''\n",
        "        How it works:\n",
        "        Download the files using HTTP requests\n",
        "        '''\n",
        "        print('\\n=== Task 2: Retrieving CER Renewable Energy Data ===')\n",
        "\n",
        "        target_files = []\n",
        "        downloaded_files = []\n",
        "\n",
        "        url = \"https://cer.gov.au/markets/reports-and-data/large-scale-renewable-energy-data\"\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        file_tags = soup.find_all('a', class_ = 'cer-accordion--table cer-button button--secondary')\n",
        "        for file in file_tags:\n",
        "            href = file.get('href', '')\n",
        "            text = file.get_text(strip = True).lower()\n",
        "\n",
        "            if 'csv' in text and ('power stations' in text and 'projects' in text):\n",
        "                full_url = f'https://www.cer.gov.au{href}'\n",
        "\n",
        "                target_files.append({\n",
        "                    'url': full_url,\n",
        "                    'filename': f\"{full_url.split('/')[-1]}.csv\"\n",
        "                })\n",
        "\n",
        "        for i, target in enumerate(target_files, 1):\n",
        "            print(f\"\\nDownloading {i}/3: {target['filename']}\")\n",
        "\n",
        "            filepath = self.download_file_http(\n",
        "                target['url'],\n",
        "                target['filename'],\n",
        "                'cer_renewable'\n",
        "            )\n",
        "\n",
        "            if filepath:\n",
        "                downloaded_files.append(filepath)\n",
        "\n",
        "            # Wait for 1 second to avoid overloading the server\n",
        "            time.sleep(1)\n",
        "        \n",
        "        print(f\"\\nSuccessfully downloaded {len(downloaded_files)}/3 CER files\")\n",
        "        return downloaded_files\n",
        "                    \n",
        "                \n",
        "\n",
        "    # Retrieve ABS Economy and Industry Data\n",
        "    def retrieve_abs_data(self):\n",
        "        '''\n",
        "        How it works:\n",
        "        Use Selenium to find the download link and click it\n",
        "        '''\n",
        "        print('\\n=== Task 3: Retrieving ABS Economy and Industry Data ===')\n",
        "\n",
        "        if not self.setup_selenium_driver('abs_data'):\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            url = 'https://www.abs.gov.au/methodologies/data-region-methodology/2011-24'\n",
        "            print(f'Loading: {url}')\n",
        "            self.driver.get(url)\n",
        "\n",
        "            # Wait for page to load\n",
        "            self.wait.until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
        "            time.sleep(3)\n",
        "\n",
        "            # Set window size to desktop to avoid mobile elements\n",
        "            self.driver.set_window_size(1920, 1080)\n",
        "            time.sleep(1)\n",
        "\n",
        "            # Scroll to data downloads section\n",
        "            downloads_section = self.driver.find_element(By.ID, 'data-downloads')\n",
        "            self.driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", downloads_section)\n",
        "            time.sleep(2)\n",
        "            print('Found and scrolled to data downloads section')\n",
        "\n",
        "            # Target the specific file\n",
        "            target_href = '/methodologies/data-region-methodology/2011-24/14100DO0003_2011-24.xlsx'\n",
        "\n",
        "            # Find the download link and click it\n",
        "            download_link = self.driver.find_element(By.CSS_SELECTOR, f'a[href=\"{target_href}\"]')\n",
        "\n",
        "            print(f'Found ABS file: {download_link.text.strip()}')\n",
        "            print(f'Downloading in progress...')\n",
        "\n",
        "            # Scroll to element and click\n",
        "            self.driver.execute_script('arguments[0].scrollIntoView(true);', download_link)\n",
        "            time.sleep(2)\n",
        "            download_link.click()\n",
        "            print('Clicked download link')\n",
        "\n",
        "            # Wait for download\n",
        "            download_dir = self.output_dir / 'abs_data'\n",
        "            downloaded_file = self.wait_for_download(download_dir, timeout=180)\n",
        "\n",
        "            # Check if the file is downloaded\n",
        "            if downloaded_file:\n",
        "                print(f'Download ABS file')\n",
        "            else:\n",
        "                print('Download failed')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'Error retrieving NGER data: {str(e)}')\n",
        "\n",
        "        finally:\n",
        "            self.close_driver()\n",
        "\n",
        "        print(f'\\nSuccessfully downloaded {len(downloaded_file)} ABS file')\n",
        "        return downloaded_file\n",
        "\n",
        "\n",
        "    # Function to run the whole script\n",
        "    def run_script(self):\n",
        "        print(f'Output directory: {self.output_dir.absolute()}')\n",
        "\n",
        "        # Run all tasks\n",
        "        self.retrieve_cer_nger_data()\n",
        "        self.retrieve_cer_renewable_data()\n",
        "        self.retrieve_abs_data()\n",
        "\n",
        "\n",
        "        # List all downloaded files\n",
        "        print(f'\\nFiles in: {self.output_dir.absolute()}')\n",
        "\n",
        "        cer_nger_dir = self.output_dir / 'cer_nger'\n",
        "        if cer_nger_dir.exists():\n",
        "            print(f'\\nCER NGER files:')\n",
        "            for file in sorted(cer_nger_dir.glob('*.csv')):\n",
        "                print(f'    {file.name}')\n",
        "\n",
        "        cer_dir = self.output_dir / 'cer_renewable'\n",
        "        if cer_dir.exists():\n",
        "            print(f'\\nCER Renewable files:')\n",
        "            for file in sorted(cer_dir.glob('*.csv')):\n",
        "                print(f'    {file.name}')\n",
        "\n",
        "        abs_dir = self.output_dir / 'abs_data'\n",
        "        if abs_dir.exists():\n",
        "            print(f'\\nABS Economy files:')\n",
        "            for file in sorted(abs_dir.glob('*.xlsx')):\n",
        "                print(f'    {file.name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "sCjOC0iAnehr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "sCjOC0iAnehr",
        "outputId": "88ced29c-26fa-4c6e-f700-abd3f5ecdfaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output directory: /Users/hyungjinkim/Desktop/USYD/2025-2/COMP5339/Assignment/comp5339/data\n",
            "\n",
            "=== Task 1: Retrieving CER NGER Data ===\n",
            "Setting download directory to: /Users/hyungjinkim/Desktop/USYD/2025-2/COMP5339/Assignment/comp5339/data/cer_nger\n",
            "Chrome WebDriver initialized\n",
            "Loading: https://data.cer.gov.au/datasets/NGER/ID0243\n",
            "API URL: https://api.cer.gov.au/datahub-public/v1/api/ODataDataset/NGER/dataset/ID0243?select%3D%2A\n",
            "\n",
            "=== Task 2: Retrieving CER Renewable Energy Data ===\n",
            "\n",
            "Downloading 1/3: power-stations-and-projects-accredited.csv\n",
            "Downloading: power-stations-and-projects-accredited.csv\n",
            "From: https://www.cer.gov.au/document/power-stations-and-projects-accredited\n",
            "Downloaded: power-stations-and-projects-accredited.csv\n",
            "\n",
            "Downloading 2/3: power-stations-and-projects-committed.csv\n",
            "Downloading: power-stations-and-projects-committed.csv\n",
            "From: https://www.cer.gov.au/document/power-stations-and-projects-committed\n",
            "Downloaded: power-stations-and-projects-committed.csv\n",
            "\n",
            "Downloading 3/3: power-stations-and-projects-probable.csv\n",
            "Downloading: power-stations-and-projects-probable.csv\n",
            "From: https://www.cer.gov.au/document/power-stations-and-projects-probable\n",
            "Downloaded: power-stations-and-projects-probable.csv\n",
            "\n",
            "Successfully downloaded 3/3 CER files\n",
            "\n",
            "=== Task 3: Retrieving ABS Economy and Industry Data ===\n",
            "Setting download directory to: /Users/hyungjinkim/Desktop/USYD/2025-2/COMP5339/Assignment/comp5339/data/abs_data\n",
            "Chrome WebDriver initialized\n",
            "Loading: https://www.abs.gov.au/methodologies/data-region-methodology/2011-24\n",
            "Found and scrolled to data downloads section\n",
            "Found ABS file: Download XLSX\n",
            "[18.75 MB]\n",
            "Downloading in progress...\n",
            "Clicked download link\n",
            "Waiting for download to complete...\n",
            "Waiting... (0s elapsed)\n",
            "Download complete: ['14100DO0003_2011-24.xlsx']\n",
            "Download ABS file\n",
            "\n",
            "Successfully downloaded 1 ABS file\n",
            "\n",
            "Files in: /Users/hyungjinkim/Desktop/USYD/2025-2/COMP5339/Assignment/comp5339/data\n",
            "\n",
            "CER NGER files:\n",
            "    NGER.ID0243.csv\n",
            "\n",
            "CER Renewable files:\n",
            "    power-stations-and-projects-accredited.csv\n",
            "    power-stations-and-projects-committed.csv\n",
            "    power-stations-and-projects-probable.csv\n",
            "\n",
            "ABS Economy files:\n",
            "    14100DO0003_2011-24.xlsx\n"
          ]
        }
      ],
      "source": [
        "download = DataRetriever()\n",
        "download.run_script()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "comp5339",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
